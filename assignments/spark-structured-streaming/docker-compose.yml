version: '3'
services:

  hf-zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: hf-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    command: /opt/kafka_2.13-3.7.0/bin/zookeeper-server-start.sh

  hf-kafka:
    image: confluentinc/cp-kafka:latest
    container_name: hf-kafka
    depends_on:
      - hf-zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: hf-zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://hf-kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "raw:1:1"
    volumes:
      - ./data:/data
      - ./src:/app/src  # Mounting src directory to /app/src inside the container
    command: /opt/kafka_2.13-3.7.0/bin/kafka-server-start.sh

  hf-pyspark-app:
    build:
      context: .
      dockerfile: ./Dockerfile
    container_name: hf-pyspark-app
    volumes:
      - ./:/app
    depends_on:
      - hf-kafka

  # airflow:
  #   image: apache/airflow:2.3.3
  #   container_name: airflow
  #   ports:
  #     - 8080:8080
  #   volumes:
  #     - ./dags:/opt/airflow/dags
  #     - ./logs:/opt/airflow/logs
  #   depends_on:
  #     - hf-kafka
  #   environment:
  #     - AIRFLOW__CORE__EXECUTOR=LocalExecutor
  #     - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False
  #     - AIRFLOW__CORE__LOAD_EXAMPLES=False
  #     - AIRFLOW__CORE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
  #     - AIRFLOW__KUBERNETES__NAMESPACE=airflow
  #     - AIRFLOW__KUBERNETES__WORKER_SERVICE_ACCOUNT_NAME=airflow-worker
  #     - AIRFLOW__KUBERNETES__WORKER_CONTAINER_REPOSITORY=apache/airflow-worker
  #     - AIRFLOW__KUBERNETES__WORKER_CONTAINER_TAG=2.3.3

volumes:
  streaming_data:
