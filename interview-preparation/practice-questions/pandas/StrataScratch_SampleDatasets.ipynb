{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_data = [\n",
    "    [1, \"Monika\", \"Arora\", 100000, datetime.date(2014, 2, 20), \"HR\"],\n",
    "    [2, \"Niharika\", \"Verma\", 80000, datetime.date(2014, 6, 11), \"Admin\"],\n",
    "    [3, \"Vishal\", \"Singhal\", 300000, datetime.date(2014, 2, 20), \"HR\"],\n",
    "    [4, \"Amitah\", \"Singh\", 500000, datetime.date(2014, 2, 20), \"Admin\"],\n",
    "    [5, \"Vivek\", \"Bhati\", 500000, datetime.date(2014, 6, 11), \"Admin\"],\n",
    "    [6, \"Vipul\", \"Diwan\", 200000, datetime.date(2014, 6, 11), \"Account\"],\n",
    "    [7, \"Satish\", \"Kumar\", 75000, datetime.date(2014, 1, 20), \"Account\"],\n",
    "    [8, \"Geetika\", \"Chauhan\", 90000, datetime.date(2014, 4, 11), \"Admin\"],\n",
    "    [9, \"Agepi\", \"Argon\", 90000, datetime.date(2015, 4, 10), \"Admin\"],\n",
    "    [10, \"Moe\", \"Acharya\", 65000, datetime.date(2015, 4, 11), \"HR\"],\n",
    "    [11, \"Nayah\", \"Laghari\", 75000, datetime.date(2014, 3, 20), \"Account\"],\n",
    "    [12, \"Jai\", \"Patel\", 85000, datetime.date(2014, 3, 21), \"HR\"]\n",
    "]\n",
    "\n",
    "worker_columns = [\"worker_id\", \"first_name\", \"last_name\", \"salary\", \"joining_date\", \"department\"]\n",
    "df = pd.DataFrame(worker_data, columns=worker_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Full Name and Highest Salary\n",
    "df[\"full_name\"] = df[\"first_name\"] + \" \" + df[\"last_name\"]\n",
    "# Find the row with the maximum salary\n",
    "max_salary_row = df.loc[df['salary'].idxmax()]\n",
    "# Create a new DataFrame with the maximum salary row\n",
    "result_df = pd.DataFrame({\n",
    "    \"full_name\": [max_salary_row[\"full_name\"]],\n",
    "    \"max_salary\": [max_salary_row['salary']]\n",
    "})\n",
    "\n",
    "# OR\n",
    "\n",
    "# # Get maximum salary\n",
    "# max_salary = df[\"salary\"].max()\n",
    "\n",
    "# # Filter DataFrame to get row with maximum salary\n",
    "# max_salary_row = df[df[\"salary\"] == max_salary]\n",
    "\n",
    "# # Create result DataFrame\n",
    "# result_df = pd.DataFrame({\n",
    "#     \"full_name\": max_salary_row[\"full_name\"],\n",
    "#     \"max_salary\": max_salary\n",
    "# })\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  department       full_name  salary\n",
      "0    Account     Vipul Diwan  200000\n",
      "1      Admin    Amitah Singh  500000\n",
      "2      Admin     Vivek Bhati  500000\n",
      "3         HR  Vishal Singhal  300000\n"
     ]
    }
   ],
   "source": [
    "# 2:  Highest salary in each department\n",
    "\n",
    "# Group by department and find the maximum salary for each department\n",
    "max_salary_df = df.groupby(\"department\").agg({\"salary\": \"max\"})\n",
    "\n",
    "# Reset index to make department a column instead of index\n",
    "max_salary_df.reset_index(inplace=True)\n",
    "# Merge with original DataFrame to get full name corresponding to maximum salary\n",
    "result_df = pd.merge(max_salary_df, df, on=[\"department\", \"salary\"])\n",
    "\n",
    "# Select only required columns\n",
    "result_df = result_df[[\"department\", \"full_name\", \"salary\"]]\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    worker_id first_name last_name  salary joining_date department  \\\n",
      "7           8    Geetika   Chauhan   90000   2014-04-11      Admin   \n",
      "8           9      Agepi     Argon   90000   2015-04-10      Admin   \n",
      "9          10        Moe   Acharya   65000   2015-04-11         HR   \n",
      "10         11      Nayah   Laghari   75000   2014-03-20    Account   \n",
      "11         12        Jai     Patel   85000   2014-03-21         HR   \n",
      "\n",
      "          full_name  \n",
      "7   Geetika Chauhan  \n",
      "8       Agepi Argon  \n",
      "9       Moe Acharya  \n",
      "10    Nayah Laghari  \n",
      "11        Jai Patel  \n"
     ]
    }
   ],
   "source": [
    "# 3: Last Five Records of Dataset\n",
    "print(df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing_campaign_data = [ \n",
    "    ('10', '2019-01-01', '101', '3', '55'),\n",
    "    ('10', '2019-01-02', '119', '5', '29'),\n",
    "    ('10', '2019-03-31', '111', '2', '149'),\n",
    "    ('11', '2019-01-02', '105', '3', '234'),\n",
    "    ('11', '2019-03-31', '120', '3', '99'),\n",
    "    ('12', '2019-01-02', '112', '2', '200'),\n",
    "    ('12', '2019-03-31', '110', '2', '299'),\n",
    "    ('13', '2019-01-05', '113', '1', '67'),\n",
    "    ('13', '2019-03-31', '118', '3', '35'),\n",
    "    ('14', '2019-01-06', '109', '5', '199'),\n",
    "    ('14', '2019-01-06', '107', '2', '27'),\n",
    "    ('14', '2019-03-31', '112', '3', '200'),\n",
    "    ('15', '2019-01-08', '105', '4', '234'),\n",
    "    ('15', '2019-01-09', '110', '4', '299'),\n",
    "    ('15', '2019-03-31', '116', '2', '499'),\n",
    "    ('16', '2019-01-10', '113', '2', '67'),\n",
    "    ('16', '2019-03-31', '107', '4', '27'),\n",
    "    ('17', '2019-01-11', '116', '2', '499'),\n",
    "    ('17', '2019-03-31', '104', '1', '154'),\n",
    "    ('18', '2019-01-12', '114', '2', '248'),\n",
    "    ('18', '2019-01-12', '113', '4', '67'),\n",
    "    ('19', '2019-01-12', '114', '3', '248'),\n",
    "    ('20', '2019-01-15', '117', '2', '999'),\n",
    "    ('21', '2019-01-16', '105', '3', '234'),\n",
    "    ('21', '2019-01-17', '114', '4', '248'),\n",
    "    ('22', '2019-01-18', '113', '3', '67'),\n",
    "    ('22', '2019-01-19', '118', '4', '35'),\n",
    "    ('23', '2019-01-20', '119', '3', '29'),\n",
    "    ('24', '2019-01-21', '114', '2', '248'),\n",
    "    ('25', '2019-01-22', '114', '2', '248'),\n",
    "    ('25', '2019-01-22', '115', '2', '72'),\n",
    "    ('25', '2019-01-24', '114', '5', '248'),\n",
    "    ('25', '2019-01-27', '115', '1', '72'),\n",
    "    ('26', '2019-01-25', '115', '1', '72'),\n",
    "    ('27', '2019-01-26', '104', '3', '154'),\n",
    "    ('28', '2019-01-27', '101', '4', '55'),\n",
    "    ('29', '2019-01-27', '111', '3', '149'),\n",
    "    ('30', '2019-01-29', '111', '1', '149'),\n",
    "    ('31', '2019-01-30', '104', '3', '154'),\n",
    "    ('32', '2019-01-31', '117', '1', '999'),\n",
    "    ('33', '2019-01-31', '117', '2', '999'),\n",
    "    ('34', '2019-01-31', '110', '3', '299'),\n",
    "    ('35', '2019-02-03', '117', '2', '999'),\n",
    "    ('36', '2019-02-04', '102', '4', '82'),\n",
    "    ('37', '2019-02-05', '102', '2', '82'),\n",
    "    ('38', '2019-02-06', '113', '2', '67'),\n",
    "    ('39', '2019-02-07', '120', '4', '99')\n",
    "]\n",
    "\n",
    "marketing_campaign_columns = [\"user_id\", \"created_at\", \"product_id\", \"quantity\", \"price\"]\n",
    "marketing_campaign_df = pd.DataFrame(marketing_campaign_data, columns=marketing_campaign_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_performance_rating_df = marketing_campaign_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad Performance Rating\n",
    "ad_performance_rating_df[\"quantity\"] = ad_performance_rating_df[\"quantity\"].astype(\"int\")\n",
    "ad_performance_rating_df = ad_performance_rating_df.groupby(\"product_id\").agg({\"quantity\": \"sum\"})\n",
    "# Reset index to include \"product_id\" as a column\n",
    "ad_performance_rating_df = ad_performance_rating_df.reset_index()\n",
    "ad_performance_rating_df = ad_performance_rating_df.rename(columns={\"quantity\": \"total_units_sold\"})\n",
    "# Define a lambda function to categorize performance\n",
    "categorize_performance = lambda x: 'Outstanding' if x >= 30 else \\\n",
    "                                    'Satisfactory' if 20 <= x <= 29 else \\\n",
    "                                    'Unsatisfactory' if 10 <= x <= 19 else \\\n",
    "                                    'Poor' if 1 <= x <= 9 else 'Unknown'\n",
    "\n",
    "# Apply the lambda function to create a new column for ad performance\n",
    "ad_performance_rating_df['ad_performance'] = ad_performance_rating_df['total_units_sold'].apply(categorize_performance)\n",
    "# # Reset index to include \"product_id\" as a column\n",
    "# ad_performance_rating_df = ad_performance_rating_df.reset_index()\n",
    "# Sort by total units sold in descending order\n",
    "ad_performance_rating_df = ad_performance_rating_df.sort_values(by='total_units_sold', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>total_units_sold</th>\n",
       "      <th>ad_performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>Unsatisfactory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>113</td>\n",
       "      <td>12</td>\n",
       "      <td>Unsatisfactory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>Unsatisfactory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>119</td>\n",
       "      <td>8</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  total_units_sold  ad_performance\n",
       "10        114                18  Unsatisfactory\n",
       "9         113                12  Unsatisfactory\n",
       "3         105                10  Unsatisfactory\n",
       "6         110                 9            Poor\n",
       "15        119                 8            Poor"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_performance_rating_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
