{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "from tableau_api_lib import TableauServerConnection\n",
    "from tableau_api_lib.utils import querying\n",
    "from tableau_api_lib.utils.common import flatten_dict_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_special_characters(text):\n",
    "    text = text.replace(' ', '%20')\n",
    "    return text\n",
    "\n",
    "def get_encoded_params(param_dict):\n",
    "    encoded_dict = {}\n",
    "    for key in param_dict.keys():\n",
    "        encoded_dict[key] = replace_special_characters(str(param_dict[key]))\n",
    "    return encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableauConnector:\n",
    "    \"\"\"\n",
    "    A class to handle the connection and querying operations with Tableau Server.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, environment=\"prod\"):\n",
    "        \"\"\"\n",
    "        Initialize the TableauConnector with the environment.\n",
    "\n",
    "        Parameters:\n",
    "            environment (str): The environment to connect to (default is \"prod\").\n",
    "        \"\"\"\n",
    "        # self.connection, self.tableau_configuration = self._create_tableau_connection(config_path, environment)\n",
    "        self.connection = None\n",
    "        self.environment = environment\n",
    "        self.tableau_configuration = None\n",
    "\n",
    "    def _create_tableau_connection(self, tableau_configuration):\n",
    "        \"\"\"\n",
    "        Create and sign in to a Tableau Server connection.\n",
    "\n",
    "        Parameters:\n",
    "            tableau_configuration (dict): The configuration details for Tableau Server.\n",
    "\n",
    "        Returns:\n",
    "            TableauServerConnection: The established Tableau Server connection.\n",
    "        \"\"\"\n",
    "        config = {self.environment: tableau_configuration[self.environment]}\n",
    "        self.connection = TableauServerConnection(config, env=self.environment)\n",
    "        self.connection.sign_in()\n",
    "\n",
    "    def _close_tableau_connection(self):\n",
    "        \"\"\"Sign out Tableau Server connection\"\"\"\n",
    "        self.connection.sign_out()\n",
    "\n",
    "    def load_yaml_config(self, file_path):\n",
    "        \"\"\"\n",
    "        Load and parse a YAML configuration file.\n",
    "\n",
    "        Parameters:\n",
    "            file_path (str): The path to the YAML file.\n",
    "\n",
    "        Returns:\n",
    "            dict: The parsed YAML content as a dictionary.\n",
    "        \"\"\"\n",
    "        with open(file_path, \"r\") as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        return config\n",
    "    \n",
    "    def read_file(self, file_name, file_type=\"xlsx\"):\n",
    "        \"\"\"\n",
    "        Read a file and return its content as a DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "            file_name (str): The name of the file to read.\n",
    "            file_type (str): The type of the file (\"xlsx\" or \"csv\").\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The content of the file as a DataFrame.\n",
    "        \"\"\"\n",
    "        if file_type == \"xlsx\":\n",
    "            return pd.read_excel(file_name, sheet_name=\"Sheet1\")\n",
    "        elif file_type == \"csv\":\n",
    "            return pd.read_csv(file_name)\n",
    "        return None\n",
    "    \n",
    "    def extract_workbook_data(self, config):\n",
    "        \"\"\"\n",
    "        Extracts workbook data from the configuration dictionary.\n",
    "\n",
    "        Args:\n",
    "            config (dict): The configuration dictionary.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: A DataFrame containing project_name, workbook_name, and view_name.\n",
    "        \"\"\"\n",
    "        workbook_data = []\n",
    "        for project in config['projects']:\n",
    "            for workbook in project['workbooks']:\n",
    "                workbook_name = workbook['name']\n",
    "                for view in workbook.get('views', []):\n",
    "                    view_name = view['name']\n",
    "                    filters = view.get('filters', {})\n",
    "                    measure_aliases = view.get('measure_aliases', {})\n",
    "                    workbook_data.append({\n",
    "                        'project_name': project['name'],\n",
    "                        'workbook_name': workbook_name,\n",
    "                        'view_name': view_name,\n",
    "                        'filters': filters,\n",
    "                        'measure_aliases': measure_aliases\n",
    "                    })\n",
    "        \n",
    "        workbook_df = pd.DataFrame(workbook_data)\n",
    "        return workbook_df\n",
    "    \n",
    "    def extract_filter_info(self, row):\n",
    "        \"\"\"\n",
    "        Extracts filter field name and value from the filters dictionary.\n",
    "\n",
    "        Args:\n",
    "            row (pd.Series): DataFrame row containing filter information.\n",
    "\n",
    "        Returns:\n",
    "            str, str: Filter field name and value.\n",
    "        \"\"\"\n",
    "        filter_value = row['filter']\n",
    "        filters = row['filters']\n",
    "        for key, values in filters.items():\n",
    "            if filter_value in values:\n",
    "                return key, filter_value\n",
    "        return None, None\n",
    "\n",
    "    def extract_query_desc(self, row):\n",
    "        \"\"\"\n",
    "        Extracts query description from the measure_aliases dictionary.\n",
    "\n",
    "        Args:\n",
    "            row (pd.Series): DataFrame row containing measure aliases information.\n",
    "\n",
    "        Returns:\n",
    "            str: Query description.\n",
    "        \"\"\"\n",
    "        return row['measure_aliases'].get(row['query_desc'])\n",
    "\n",
    "    def merge_dataframes(self, excel_data_df, workbooks_df):\n",
    "        \"\"\"\n",
    "        Merges two DataFrames based on 'workbook_name' and 'view_name' columns.\n",
    "\n",
    "        Args:\n",
    "            excel_data_df (pandas.DataFrame):  excel_data DataFrame.\n",
    "            workbooks_df (pandas.DataFrame):  workbooks DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: A DataFrame containing the merged data.\n",
    "        \"\"\"\n",
    "        excel_data_df.rename(columns={\"dashboard_name\": \"workbook_name\", \"tab_name\": \"view_name\"}, inplace=True)\n",
    "        merged_df = pd.merge(excel_data_df, workbooks_df, on=['workbook_name', 'view_name'], how='inner')\n",
    "        merged_df['filter_field_name'], merged_df['filter_field_value'] = zip(*merged_df.apply(self.extract_filter_info, axis=1))\n",
    "        merged_df['measure_name'] = merged_df.apply(self.extract_query_desc, axis=1)\n",
    "        return merged_df\n",
    "    \n",
    "    def get_workbook_id(self, project_name, workbook_name):\n",
    "        \"\"\"\n",
    "        Get the workbook ID for a specific project and workbook name.\n",
    "\n",
    "        Parameters:\n",
    "            project_name (str): The name of the Tableau project.\n",
    "            workbook_name (str): The name of the workbook.\n",
    "\n",
    "        Returns:\n",
    "            str: The ID of the workbook.\n",
    "        \"\"\"\n",
    "        workbooks_df = querying.get_workbooks_dataframe(self.connection)\n",
    "        workbooks_df = flatten_dict_column(workbooks_df, keys=['name', 'id'], col_name='project')\n",
    "        \n",
    "        target_workbook_df = workbooks_df[\n",
    "            (workbooks_df[\"project_name\"] == project_name) &\n",
    "            (workbooks_df[\"name\"] == workbook_name)\n",
    "        ].dropna()\n",
    "        \n",
    "        workbook_id = target_workbook_df[\"id\"].values[0]\n",
    "        return workbook_id\n",
    "\n",
    "    def generate_filter_params(self, field_name, field_value):\n",
    "        \"\"\"\n",
    "        Generate filter parameters based on field name and value.\n",
    "\n",
    "        Args:\n",
    "            field_name (str): The name of the field to filter on. Ex: Education\n",
    "            field_value (str): The value of the field to filter on. EX: Bachelor's Degree\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the filter parameter.\n",
    "        \"\"\"\n",
    "        # https://help.tableau.com/current/api/rest_api/en-us/REST/rest_api_concepts_filtering_and_sorting.htm#Filter-query-views\n",
    "        param_dict = {f\"filter_for_{field_value.lower().replace(' ', '_')}\": f\"vf_{field_name}={field_value}\"}\n",
    "        return param_dict\n",
    "    \n",
    "    def get_view_data(self, tableau_configuration, df, is_filter=False):\n",
    "        \"\"\"\n",
    "        Retrieve the view data for a given project, workbook, and view name from tableau_configuration.\n",
    "\n",
    "        Parameters:\n",
    "            tableau_configuration (dict): Configuration details for Tableau.\n",
    "            df (pd.DataFrame): DataFrame containing project_name, workbook_name, view_name, and other columns.\n",
    "            is_filter (bool): Whether to apply filters to the query.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing the original columns from df and additional columns from view data.\n",
    "        \"\"\"\n",
    "        workbook_cache = {}\n",
    "        output_df_list = []\n",
    "\n",
    "        self._create_tableau_connection(tableau_configuration)\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            project_name = row[\"project_name\"]\n",
    "            workbook_name = row[\"workbook_name\"]\n",
    "            view_name = row[\"view_name\"]\n",
    "            cache_key = (project_name, workbook_name)\n",
    "            if cache_key not in workbook_cache:\n",
    "                workbook_id = self.get_workbook_id(project_name, workbook_name)\n",
    "                workbook_cache[cache_key] = {\n",
    "                    \"workbook_id\": workbook_id,\n",
    "                    \"views_df\": querying.get_views_for_workbook_dataframe(self.connection, workbook_id=workbook_id)\n",
    "                }\n",
    "\n",
    "            target_views_df = workbook_cache[cache_key][\"views_df\"]\n",
    "            filtered_df = target_views_df[target_views_df[\"name\"] == view_name]\n",
    "\n",
    "            for _, value in filtered_df.iterrows():\n",
    "                view_id = value[\"id\"]\n",
    "                if is_filter:\n",
    "                    filter_param_dict = {\"filter_dict\": f\"vf_{row['filter_field_name']}={row['filter_field_value']}\"}\n",
    "                    filter_param_dict = get_encoded_params(filter_param_dict)\n",
    "                    view_data_df = querying.get_view_data_dataframe(self.connection, view_id=view_id, parameter_dict=filter_param_dict)\n",
    "                else:\n",
    "                    view_data_df = querying.get_view_data_dataframe(self.connection, view_id=view_id)\n",
    "                \n",
    "                view_data_columns = list(view_data_df.columns)\n",
    "                view_data_df = view_data_df.set_index(view_data_columns[0]).transpose().reset_index(drop=True)\n",
    "                \n",
    "                for _, view_data_row in view_data_df.iterrows():\n",
    "                    combined_row = row.to_dict()\n",
    "                    combined_row['view_id'] = view_id\n",
    "                    # Adding the dashboard value\n",
    "                    combined_row[\"dash_board_value\"] = view_data_row.get(row[\"measure_name\"], None)\n",
    "                    # Adding the match result\n",
    "                    combined_row[\"is_match\"] = \"Yes\" if combined_row.get(\"result\") == combined_row[\"dash_board_value\"] else \"No\"\n",
    "                    # Adding date and time \n",
    "                    combined_row[\"created_at\"] = pd.Timestamp.now()\n",
    "                    # Combining the data\n",
    "                    combined_data = pd.DataFrame([combined_row])\n",
    "                    output_df_list.append(combined_data)\n",
    "\n",
    "        output_df = pd.concat(output_df_list, ignore_index=True)\n",
    "        output_df.drop(['filters', 'measure_aliases'], axis=1, inplace=True)\n",
    "        return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_connector_obj = TableauConnector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\office\\\\rohit-workspace\\\\tableau\\\\sample_dashboard.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m input_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124moffice\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mrohit-workspace\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtableau\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124msample_dashboard.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m configuration_data \u001b[38;5;241m=\u001b[39m tableau_connector_obj\u001b[38;5;241m.\u001b[39mload_yaml_config(config_file_path)\n\u001b[1;32m----> 4\u001b[0m excel_data_df \u001b[38;5;241m=\u001b[39m \u001b[43mtableau_connector_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 62\u001b[0m, in \u001b[0;36mTableauConnector.read_file\u001b[1;34m(self, file_name, file_type)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03mRead a file and return its content as a DataFrame.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m    pd.DataFrame: The content of the file as a DataFrame.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSheet1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m file_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(file_name)\n",
      "File \u001b[1;32mc:\\office\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\office\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mc:\\office\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\office\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\office\\\\rohit-workspace\\\\tableau\\\\sample_dashboard.xlsx'"
     ]
    }
   ],
   "source": [
    "config_file_path = \"C:\\\\office\\\\rohit-workspace\\\\tableau\\\\parameters.yml\"\n",
    "input_file_path = \"C:\\\\office\\\\rohit-workspace\\\\tableau\\\\sample_dashboard.xlsx\"\n",
    "configuration_data = tableau_connector_obj.load_yaml_config(config_file_path)\n",
    "excel_data_df = tableau_connector_obj.read_file(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'excel_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mexcel_data_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'excel_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "excel_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbooks_df = tableau_connector_obj.extract_workbook_data(configuration_data[\"tableau_configuration\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>workbook_name</th>\n",
       "      <th>view_name</th>\n",
       "      <th>filters</th>\n",
       "      <th>measure_aliases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "      <td>Rohit's Sample Workbook</td>\n",
       "      <td>KPI</td>\n",
       "      <td>{'Education': ['Associates Degree', 'Master's ...</td>\n",
       "      <td>{'Total Employee Count': 'Employee Count', 'To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athena Dashboards</td>\n",
       "      <td>Sales Performance Dashboard</td>\n",
       "      <td>New Prescriber Details</td>\n",
       "      <td>{'geography': ['North America', 'Europe']}</td>\n",
       "      <td>{'Cancelled Patients- Cancelled PUMs (Nation)'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athena Dashboards</td>\n",
       "      <td>Sales Performance Dashboard</td>\n",
       "      <td>Patient Overview</td>\n",
       "      <td>{'geography': ['North America', 'Europe']}</td>\n",
       "      <td>{'Cancelled Patients- Cancelled PUMs (Nation)'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        project_name                workbook_name               view_name  \\\n",
       "0            default      Rohit's Sample Workbook                     KPI   \n",
       "1  Athena Dashboards  Sales Performance Dashboard  New Prescriber Details   \n",
       "2  Athena Dashboards  Sales Performance Dashboard        Patient Overview   \n",
       "\n",
       "                                             filters  \\\n",
       "0  {'Education': ['Associates Degree', 'Master's ...   \n",
       "1         {'geography': ['North America', 'Europe']}   \n",
       "2         {'geography': ['North America', 'Europe']}   \n",
       "\n",
       "                                     measure_aliases  \n",
       "0  {'Total Employee Count': 'Employee Count', 'To...  \n",
       "1  {'Cancelled Patients- Cancelled PUMs (Nation)'...  \n",
       "2  {'Cancelled Patients- Cancelled PUMs (Nation)'...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workbooks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'excel_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m tableau_connector_obj\u001b[38;5;241m.\u001b[39mmerge_dataframes(\u001b[43mexcel_data_df\u001b[49m, workbooks_df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'excel_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "merged_df = tableau_connector_obj.merge_dataframes(excel_data_df, workbooks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmerged_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m view_df \u001b[38;5;241m=\u001b[39m tableau_connector_obj\u001b[38;5;241m.\u001b[39mget_view_data(configuration_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtableau_configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43mmerged_df\u001b[49m, is_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "view_df = tableau_connector_obj.get_view_data(configuration_data[\"tableau_configuration\"], merged_df, is_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'view_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mview_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'view_df' is not defined"
     ]
    }
   ],
   "source": [
    "view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'view_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mview_df\u001b[49m\u001b[38;5;241m.\u001b[39mdtypes\n",
      "\u001b[1;31mNameError\u001b[0m: name 'view_df' is not defined"
     ]
    }
   ],
   "source": [
    "view_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_user = \"postgres\"\n",
    "db_password = \"root\"\n",
    "db_host = \"localhost\"\n",
    "db_port = \"5432\"\n",
    "db_name = \"rohit\"\n",
    "db_table_name = \"tableau_dashboard_data\"\n",
    "\n",
    "# Replace the connection string with your PostgreSQL connection details\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "view_df.to_sql(db_table_name, engine, if_exists='replace', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
